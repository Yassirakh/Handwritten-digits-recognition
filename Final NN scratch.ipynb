{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Baseline MLP for MNIST dataset\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "def loss(predicted_output,desired_output):\n",
    "    return 1/2*(desired_output-predicted_output)**2\n",
    "\n",
    "class NeuralNetwork() :\n",
    "    def __init__ (self, inputLayerNeuronsNumber , hiddenLayerNeuronsNumber, outputLayerNeuronsNumber):\n",
    "        self.inputLayerNeuronsNumber = inputLayerNeuronsNumber\n",
    "        self.hiddenLayerNeuronsNumber = hiddenLayerNeuronsNumber\n",
    "        self.outputLayerNeuronsNumber = outputLayerNeuronsNumber\n",
    "        self.learning_rate = 0.1\n",
    "        #He initialization\n",
    "        self.hidden_weights = np.random.randn(hiddenLayerNeuronsNumber,inputLayerNeuronsNumber)*np.sqrt(2/inputLayerNeuronsNumber)\n",
    "        self.hidden_bias = np.zeros([hiddenLayerNeuronsNumber,1])\n",
    "        self.output_weights = np.random.randn(outputLayerNeuronsNumber,hiddenLayerNeuronsNumber)\n",
    "        self.output_bias = np.zeros([outputLayerNeuronsNumber,1])\n",
    "        self.loss = []\n",
    "        \n",
    "        \n",
    "    def train(self, inputs, desired_output):\n",
    "        \n",
    "        hidden_layer_in = np.dot(self.hidden_weights, inputs) + self.hidden_bias\n",
    "        hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "        \n",
    "        output_layer_in = np.dot(self.output_weights, hidden_layer_out) + self.output_bias\n",
    "        predicted_output = sigmoid(output_layer_in)\n",
    "        \n",
    "        error = desired_output - predicted_output\n",
    "        d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "        \n",
    "        error_hidden_layer = d_predicted_output.T.dot(self.output_weights)\n",
    "        d_hidden_layer = error_hidden_layer.T * sigmoid_derivative(hidden_layer_out)\n",
    "                \n",
    "        self.output_weights += hidden_layer_out.dot(d_predicted_output.T).T * self.learning_rate\n",
    "        self.output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * self.learning_rate\n",
    "        \n",
    "        self.hidden_weights += inputs.dot(d_hidden_layer.T).T * self.learning_rate\n",
    "        self.hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.loss.append(loss(predicted_output,desired_output))\n",
    "        \n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        #Forward Pass\n",
    "        hidden_layer_in = np.dot(self.hidden_weights, inputs) + self.hidden_bias\n",
    "        hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "        output_layer_in = np.dot(self.output_weights, hidden_layer_out) + self.output_bias\n",
    "        predicted_output = sigmoid(output_layer_in)\n",
    "        return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Training set shape :  (50000, 784)\n",
      "Test set shape :  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "\n",
    "#Importing dataset\n",
    "X, y = loadlocal_mnist(images_path='./data/train-images.idx3-ubyte',labels_path='./data/train-labels.idx1-ubyte')\n",
    "\n",
    "#Spliting dataset\n",
    "num_train = 50000\n",
    "num_test = 10000\n",
    "X_train = X[:num_train, :]/255\n",
    "y_train = np.zeros((num_train, 10))\n",
    "y_train[np.arange(0, num_train) ,y[:num_train]] = 1  \n",
    "\n",
    "X_test = X[num_train:, :]/255\n",
    "y_test = np.zeros((num_test, 10))\n",
    "y_test[np.arange(0, num_test) ,y[y.size - num_test:]] = 1\n",
    "\n",
    "print(\"Training set shape : \",X_train.shape)\n",
    "print(\"Test set shape : \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration :  999 [[2.55089656e-16]\n",
      " [1.49867487e-09]\n",
      " [1.00603335e-13]\n",
      " [1.86569303e-16]\n",
      " [2.11171138e-08]\n",
      " [1.30649735e-10]\n",
      " [2.04254433e-06]\n",
      " [4.33064287e-13]\n",
      " [4.43691995e-05]\n",
      " [5.19481048e-06]]\n",
      "loss at iteration :  1999 [[2.79383541e-07]\n",
      " [2.64950463e-16]\n",
      " [3.47679790e-15]\n",
      " [1.39273116e-12]\n",
      " [6.91560933e-24]\n",
      " [8.77519710e-10]\n",
      " [5.67571921e-08]\n",
      " [1.04086380e-19]\n",
      " [4.87139501e-07]\n",
      " [1.26584981e-22]]\n",
      "loss at iteration :  2999 [[3.78598747e-08]\n",
      " [1.51824603e-07]\n",
      " [1.82826755e-06]\n",
      " [1.18281469e-05]\n",
      " [2.01499123e-07]\n",
      " [6.66500708e-06]\n",
      " [5.95542055e-07]\n",
      " [4.67850187e-09]\n",
      " [6.10786559e-04]\n",
      " [2.50359740e-04]]\n",
      "loss at iteration :  3999 [[5.31887381e-09]\n",
      " [8.97107833e-09]\n",
      " [1.78551000e-02]\n",
      " [1.04265514e-13]\n",
      " [4.20606410e-07]\n",
      " [1.40204847e-06]\n",
      " [3.01346689e-05]\n",
      " [5.76629406e-10]\n",
      " [4.19416283e-07]\n",
      " [1.69933129e-07]]\n",
      "loss at iteration :  4999 [[2.41656777e-08]\n",
      " [9.45846565e-07]\n",
      " [2.35016507e-04]\n",
      " [6.81350883e-13]\n",
      " [9.81083406e-10]\n",
      " [7.30830044e-13]\n",
      " [4.56199065e-03]\n",
      " [6.81401680e-11]\n",
      " [8.76977487e-03]\n",
      " [6.83817382e-08]]\n",
      "loss at iteration :  5999 [[2.23172953e-13]\n",
      " [1.58658058e-13]\n",
      " [1.35897774e-10]\n",
      " [9.16955594e-07]\n",
      " [7.75604626e-08]\n",
      " [1.63715847e-10]\n",
      " [1.00358276e-11]\n",
      " [4.33500684e-06]\n",
      " [4.44340681e-07]\n",
      " [2.45909069e-05]]\n",
      "loss at iteration :  6999 [[1.37820520e-12]\n",
      " [1.88415821e-13]\n",
      " [5.75296532e-09]\n",
      " [6.78400133e-11]\n",
      " [3.48139639e-06]\n",
      " [1.99578052e-09]\n",
      " [6.77793536e-13]\n",
      " [3.51012167e-05]\n",
      " [2.47888524e-05]\n",
      " [7.23598634e-03]]\n",
      "loss at iteration :  7999 [[1.57060487e-10]\n",
      " [2.05145649e-14]\n",
      " [6.21216123e-10]\n",
      " [2.89590940e-11]\n",
      " [2.73947397e-04]\n",
      " [2.03640211e-10]\n",
      " [2.02112801e-07]\n",
      " [1.24576488e-07]\n",
      " [3.25519440e-05]\n",
      " [4.11309584e-08]]\n",
      "loss at iteration :  8999 [[4.55999838e-11]\n",
      " [7.21814043e-08]\n",
      " [7.89501694e-10]\n",
      " [1.02585091e-02]\n",
      " [5.12126441e-04]\n",
      " [2.80719730e-04]\n",
      " [6.90348872e-11]\n",
      " [5.28713307e-07]\n",
      " [1.45958538e-05]\n",
      " [1.07552486e-03]]\n",
      "loss at iteration :  9999 [[1.48928262e-05]\n",
      " [9.35397585e-11]\n",
      " [2.48657972e-06]\n",
      " [1.02370505e-07]\n",
      " [1.94313830e-09]\n",
      " [1.53727805e-04]\n",
      " [6.64901326e-13]\n",
      " [8.23949020e-05]\n",
      " [4.21092150e-08]\n",
      " [7.69586120e-03]]\n",
      "loss at iteration :  10999 [[2.36762098e-07]\n",
      " [2.09030218e-15]\n",
      " [3.02962169e-10]\n",
      " [9.59284675e-11]\n",
      " [4.94667212e-12]\n",
      " [2.92389560e-15]\n",
      " [1.33225539e-06]\n",
      " [3.09117907e-17]\n",
      " [7.50717736e-10]\n",
      " [6.17612298e-15]]\n",
      "loss at iteration :  11999 [[2.64330872e-12]\n",
      " [6.28675767e-10]\n",
      " [8.21648093e-04]\n",
      " [4.32055578e-03]\n",
      " [1.97600638e-19]\n",
      " [1.17997966e-08]\n",
      " [7.81525106e-20]\n",
      " [5.94142118e-15]\n",
      " [4.37046355e-04]\n",
      " [2.64507388e-14]]\n",
      "loss at iteration :  12999 [[9.02448279e-05]\n",
      " [1.08536386e-15]\n",
      " [8.86079993e-10]\n",
      " [1.26995711e-14]\n",
      " [7.47287154e-05]\n",
      " [2.71048238e-11]\n",
      " [1.06824475e-07]\n",
      " [1.92711191e-07]\n",
      " [1.93952435e-06]\n",
      " [1.11435075e-01]]\n",
      "loss at iteration :  13999 [[1.08412330e-05]\n",
      " [2.27877845e-09]\n",
      " [1.22249492e-03]\n",
      " [1.14838623e-10]\n",
      " [1.12713640e-06]\n",
      " [1.29680767e-07]\n",
      " [6.85388750e-02]\n",
      " [1.19070568e-07]\n",
      " [3.02088129e-06]\n",
      " [2.92749815e-05]]\n",
      "loss at iteration :  14999 [[1.92601489e-08]\n",
      " [8.96961049e-13]\n",
      " [1.77950333e-07]\n",
      " [2.71011770e-07]\n",
      " [4.59851664e-06]\n",
      " [1.01270891e-04]\n",
      " [7.20123124e-11]\n",
      " [1.81296034e-02]\n",
      " [8.88423023e-06]\n",
      " [2.34210841e-02]]\n",
      "loss at iteration :  15999 [[1.26659794e-10]\n",
      " [3.03901273e-01]\n",
      " [2.68170670e-04]\n",
      " [1.53213538e-06]\n",
      " [2.21734006e-07]\n",
      " [9.40491536e-09]\n",
      " [7.89005396e-09]\n",
      " [1.19263885e-02]\n",
      " [2.30910873e-05]\n",
      " [3.89596866e-05]]\n",
      "loss at iteration :  16999 [[5.31171080e-12]\n",
      " [8.75832516e-07]\n",
      " [1.02656779e-04]\n",
      " [7.48997734e-07]\n",
      " [3.51435317e-15]\n",
      " [1.08106912e-10]\n",
      " [3.54905945e-13]\n",
      " [5.01698137e-06]\n",
      " [2.90155278e-05]\n",
      " [1.70532292e-04]]\n",
      "loss at iteration :  17999 [[1.58132332e-08]\n",
      " [2.62424347e-05]\n",
      " [1.74079300e-08]\n",
      " [1.13234743e-09]\n",
      " [2.53242286e-10]\n",
      " [1.03560040e-05]\n",
      " [9.92148787e-10]\n",
      " [1.01098487e-10]\n",
      " [7.60556048e-05]\n",
      " [3.09607818e-06]]\n",
      "loss at iteration :  18999 [[2.69187955e-10]\n",
      " [3.15752276e-11]\n",
      " [5.47053035e-09]\n",
      " [3.04176968e-09]\n",
      " [1.97394094e-04]\n",
      " [1.22278721e-03]\n",
      " [9.00717459e-07]\n",
      " [3.11135835e-11]\n",
      " [1.00530298e-05]\n",
      " [3.04995619e-06]]\n",
      "loss at iteration :  19999 [[2.15180568e-12]\n",
      " [6.43078515e-07]\n",
      " [6.00898788e-07]\n",
      " [5.60416192e-08]\n",
      " [1.39251485e-17]\n",
      " [4.49053806e-14]\n",
      " [1.59115903e-09]\n",
      " [4.77268594e-12]\n",
      " [3.68014202e-09]\n",
      " [9.93411219e-15]]\n",
      "loss at iteration :  20999 [[1.23092361e-10]\n",
      " [9.42078868e-08]\n",
      " [7.24541078e-08]\n",
      " [6.43655419e-08]\n",
      " [1.18451372e-01]\n",
      " [5.93022779e-08]\n",
      " [1.65882281e-04]\n",
      " [2.39576251e-12]\n",
      " [8.70769057e-07]\n",
      " [1.22689175e-01]]\n",
      "loss at iteration :  21999 [[1.86376126e-16]\n",
      " [2.67320837e-13]\n",
      " [2.18802331e-10]\n",
      " [9.00065287e-13]\n",
      " [7.17121230e-07]\n",
      " [1.21277868e-09]\n",
      " [2.42549041e-09]\n",
      " [4.82494748e-10]\n",
      " [1.92222943e-06]\n",
      " [3.43115318e-05]]\n",
      "loss at iteration :  22999 [[3.46173703e-09]\n",
      " [5.16566055e-08]\n",
      " [1.63669646e-05]\n",
      " [9.53506322e-06]\n",
      " [1.19016964e-15]\n",
      " [1.51036855e-06]\n",
      " [7.99746761e-12]\n",
      " [1.26076835e-16]\n",
      " [1.42584591e-05]\n",
      " [2.30892632e-11]]\n",
      "loss at iteration :  23999 [[1.81223024e-12]\n",
      " [4.54838600e-12]\n",
      " [3.10897333e-09]\n",
      " [6.21812120e-10]\n",
      " [6.15063922e-03]\n",
      " [5.90796046e-09]\n",
      " [4.03307643e-09]\n",
      " [3.26601099e-08]\n",
      " [1.04662238e-03]\n",
      " [8.72455345e-03]]\n",
      "loss at iteration :  24999 [[2.35451791e-11]\n",
      " [1.07988997e-09]\n",
      " [5.53745931e-11]\n",
      " [1.12319367e-04]\n",
      " [8.12016279e-06]\n",
      " [1.63948068e-06]\n",
      " [8.27148060e-10]\n",
      " [2.36413536e-05]\n",
      " [1.18454583e-05]\n",
      " [5.30785818e-05]]\n",
      "loss at iteration :  25999 [[4.29506226e-16]\n",
      " [7.25003379e-10]\n",
      " [6.78593939e-06]\n",
      " [3.96798654e-16]\n",
      " [2.59027408e-10]\n",
      " [1.06039713e-10]\n",
      " [1.05347191e-07]\n",
      " [6.20076732e-18]\n",
      " [1.49540765e-05]\n",
      " [7.65269015e-10]]\n",
      "loss at iteration :  26999 [[1.19868491e-07]\n",
      " [1.33051671e-14]\n",
      " [1.33141507e-05]\n",
      " [1.77508103e-05]\n",
      " [7.70140157e-18]\n",
      " [1.26271280e-09]\n",
      " [2.45201789e-13]\n",
      " [2.82460380e-17]\n",
      " [6.47237379e-13]\n",
      " [3.85421808e-15]]\n",
      "loss at iteration :  27999 [[2.37435648e-10]\n",
      " [8.55479551e-11]\n",
      " [5.81167974e-09]\n",
      " [1.16435212e-06]\n",
      " [4.00192335e-16]\n",
      " [2.84602055e-06]\n",
      " [5.51000574e-11]\n",
      " [8.76158269e-19]\n",
      " [1.42984501e-07]\n",
      " [2.45881992e-12]]\n",
      "loss at iteration :  28999 [[6.17056198e-09]\n",
      " [1.34934417e-10]\n",
      " [1.99718206e-05]\n",
      " [9.01660966e-08]\n",
      " [4.54560468e-15]\n",
      " [1.27430598e-06]\n",
      " [7.36929219e-10]\n",
      " [1.24437680e-17]\n",
      " [1.34535424e-04]\n",
      " [1.14572503e-13]]\n",
      "loss at iteration :  29999 [[5.81917171e-11]\n",
      " [4.63868274e-04]\n",
      " [3.54863179e-04]\n",
      " [3.08087686e-05]\n",
      " [6.99525285e-04]\n",
      " [5.04059642e-10]\n",
      " [2.35022250e-12]\n",
      " [2.14196451e-04]\n",
      " [6.03396752e-08]\n",
      " [2.14791431e-09]]\n",
      "loss at iteration :  30999 [[1.26985359e-11]\n",
      " [6.04621805e-06]\n",
      " [2.66969480e-06]\n",
      " [8.84977851e-03]\n",
      " [2.45866988e-12]\n",
      " [1.80397593e-06]\n",
      " [1.92800925e-08]\n",
      " [7.51675690e-13]\n",
      " [8.97640972e-04]\n",
      " [2.58069289e-09]]\n",
      "loss at iteration :  31999 [[1.81776012e-04]\n",
      " [4.31394159e-09]\n",
      " [3.33072161e-10]\n",
      " [2.19967172e-02]\n",
      " [2.08674122e-14]\n",
      " [9.85785075e-05]\n",
      " [1.21780182e-06]\n",
      " [2.60369966e-10]\n",
      " [5.85544313e-05]\n",
      " [1.82977178e-06]]\n",
      "loss at iteration :  32999 [[5.41348140e-16]\n",
      " [1.24133512e-08]\n",
      " [7.47768336e-06]\n",
      " [1.31212626e-16]\n",
      " [2.98750327e-07]\n",
      " [4.50809546e-10]\n",
      " [1.88719478e-06]\n",
      " [6.03316468e-10]\n",
      " [8.65463807e-08]\n",
      " [2.09787407e-06]]\n",
      "loss at iteration :  33999 [[1.66552675e-10]\n",
      " [5.51530854e-07]\n",
      " [2.36042574e-09]\n",
      " [2.05692205e-05]\n",
      " [1.41092528e-04]\n",
      " [5.88660251e-06]\n",
      " [7.43673844e-13]\n",
      " [1.70242947e-03]\n",
      " [6.60047327e-05]\n",
      " [2.63275692e-03]]\n",
      "loss at iteration :  34999 [[4.09834413e-07]\n",
      " [1.28073355e-18]\n",
      " [1.78947448e-03]\n",
      " [9.80692503e-07]\n",
      " [1.33151438e-14]\n",
      " [2.05738115e-08]\n",
      " [6.16738443e-11]\n",
      " [4.88042704e-10]\n",
      " [4.62947181e-09]\n",
      " [5.30249697e-12]]\n",
      "loss at iteration :  35999 [[9.37404811e-06]\n",
      " [6.89257007e-15]\n",
      " [2.76236758e-06]\n",
      " [9.06962531e-08]\n",
      " [2.28031812e-10]\n",
      " [4.77569568e-07]\n",
      " [4.94623590e-04]\n",
      " [1.46546426e-11]\n",
      " [1.78662310e-11]\n",
      " [9.93406450e-14]]\n",
      "loss at iteration :  36999 [[3.11645686e-04]\n",
      " [6.55358087e-11]\n",
      " [1.25046385e-05]\n",
      " [9.77703730e-07]\n",
      " [5.50559400e-11]\n",
      " [1.43465465e-04]\n",
      " [3.77592117e-06]\n",
      " [1.35488768e-13]\n",
      " [2.30795667e-06]\n",
      " [2.20288477e-10]]\n",
      "loss at iteration :  37999 [[7.29406153e-13]\n",
      " [1.98363609e-13]\n",
      " [3.52255508e-06]\n",
      " [1.93978989e-03]\n",
      " [2.66631135e-14]\n",
      " [1.19759051e-08]\n",
      " [6.10985919e-15]\n",
      " [3.59406891e-08]\n",
      " [1.69784566e-09]\n",
      " [9.74528328e-11]]\n",
      "loss at iteration :  38999 [[4.76522328e-13]\n",
      " [1.10755928e-05]\n",
      " [4.52208252e-12]\n",
      " [6.14477704e-06]\n",
      " [2.54519791e-04]\n",
      " [7.40076867e-07]\n",
      " [1.31889534e-09]\n",
      " [1.43920074e-07]\n",
      " [1.12342127e-05]\n",
      " [1.52436368e-05]]\n",
      "loss at iteration :  39999 [[6.54090172e-09]\n",
      " [3.88595623e-10]\n",
      " [6.34347445e-06]\n",
      " [1.98516681e-07]\n",
      " [1.18413611e-16]\n",
      " [2.10190844e-01]\n",
      " [3.54948908e-01]\n",
      " [5.01222007e-20]\n",
      " [6.19137963e-06]\n",
      " [3.18694954e-16]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration :  40999 [[4.35159184e-14]\n",
      " [1.59633330e-05]\n",
      " [6.06827139e-09]\n",
      " [9.51670776e-07]\n",
      " [4.62791224e-12]\n",
      " [4.15965854e-09]\n",
      " [4.45614306e-06]\n",
      " [3.32076050e-11]\n",
      " [6.72778306e-04]\n",
      " [1.65204587e-06]]\n",
      "loss at iteration :  41999 [[4.61393998e-01]\n",
      " [1.98785448e-17]\n",
      " [3.55213888e-06]\n",
      " [9.83602254e-18]\n",
      " [3.79193390e-05]\n",
      " [1.95553627e-14]\n",
      " [6.05901092e-03]\n",
      " [2.62809695e-13]\n",
      " [4.24220858e-10]\n",
      " [1.20029756e-06]]\n",
      "loss at iteration :  42999 [[3.59452273e-07]\n",
      " [4.32107452e-04]\n",
      " [1.47817060e-04]\n",
      " [5.62269912e-06]\n",
      " [5.13562550e-06]\n",
      " [9.85719183e-06]\n",
      " [2.16905009e-05]\n",
      " [1.49040371e-06]\n",
      " [1.29628929e-04]\n",
      " [1.00748348e-07]]\n",
      "loss at iteration :  43999 [[6.40457071e-09]\n",
      " [1.91866974e-13]\n",
      " [2.08436005e-08]\n",
      " [7.91811237e-10]\n",
      " [8.73255222e-05]\n",
      " [8.07244746e-06]\n",
      " [4.64353623e-08]\n",
      " [2.11418141e-06]\n",
      " [8.51228864e-05]\n",
      " [3.26468450e-03]]\n",
      "loss at iteration :  44999 [[2.11268513e-07]\n",
      " [7.50516028e-09]\n",
      " [2.38506626e-09]\n",
      " [1.12264583e-08]\n",
      " [6.57948984e-18]\n",
      " [2.07672810e-07]\n",
      " [9.57812513e-13]\n",
      " [6.77809630e-17]\n",
      " [5.55786887e-04]\n",
      " [1.50959458e-14]]\n",
      "loss at iteration :  45999 [[4.53052970e-08]\n",
      " [9.47113460e-04]\n",
      " [1.02566562e-04]\n",
      " [1.02634588e-06]\n",
      " [1.35437584e-05]\n",
      " [2.71560820e-05]\n",
      " [1.48054608e-06]\n",
      " [1.58056285e-07]\n",
      " [2.64758900e-04]\n",
      " [1.03632599e-08]]\n",
      "loss at iteration :  46999 [[1.07576910e-05]\n",
      " [6.28686685e-07]\n",
      " [4.35269910e-07]\n",
      " [6.47006293e-08]\n",
      " [6.46988554e-07]\n",
      " [1.86368947e-08]\n",
      " [3.98596987e-07]\n",
      " [8.72891147e-05]\n",
      " [2.54129107e-06]\n",
      " [3.44944664e-07]]\n",
      "loss at iteration :  47999 [[1.11603721e-04]\n",
      " [2.12223914e-15]\n",
      " [1.19800635e-05]\n",
      " [2.97741690e-06]\n",
      " [2.76288673e-19]\n",
      " [1.79293911e-08]\n",
      " [2.32607948e-10]\n",
      " [4.22262682e-16]\n",
      " [7.98967365e-11]\n",
      " [1.76711099e-13]]\n",
      "loss at iteration :  48999 [[7.16734879e-06]\n",
      " [1.66743979e-10]\n",
      " [1.46014376e-04]\n",
      " [1.52974872e-08]\n",
      " [1.01525015e-05]\n",
      " [3.36606207e-03]\n",
      " [8.84255734e-03]\n",
      " [3.24152611e-11]\n",
      " [3.91753702e-12]\n",
      " [1.27564655e-09]]\n",
      "loss at iteration :  49999 [[9.51149033e-15]\n",
      " [2.32315508e-07]\n",
      " [1.25680627e-06]\n",
      " [1.17806044e-04]\n",
      " [6.11307216e-09]\n",
      " [3.47005296e-06]\n",
      " [1.46525738e-12]\n",
      " [1.20521862e-09]\n",
      " [2.13486758e-03]\n",
      " [1.62103988e-05]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nn=NeuralNetwork(784,350,10)\n",
    "\n",
    "    \n",
    "for i in range(X_train.shape[0]):\n",
    "    inputs = np.array(X_train[i, :].reshape(-1,1))\n",
    "    desired_output = np.array(y_train[i, :].reshape(-1,1))\n",
    "    nn.train(inputs, desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  96.07  %\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for i in range(X_test.shape[0]): \n",
    "    inputs = np.array(X_test[i].reshape(-1,1))\n",
    "    prediction_list.append(nn.predict(inputs))\n",
    "\n",
    "correct_counter = 0\n",
    "for i in range(len(prediction_list)):\n",
    "    out_index = np.where(prediction_list[i] == np.amax(prediction_list[i]))[0][0]\n",
    "    \n",
    "    if y_test[i][out_index] == 1:\n",
    "        correct_counter+=1\n",
    "\n",
    "accuracy = correct_counter/num_test\n",
    "\n",
    "print(\"Accuracy is : \",accuracy*100,\" %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
